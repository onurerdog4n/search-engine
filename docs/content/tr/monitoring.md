# Monitoring, Logging ve Observability

## üìä Genel Bakƒ±≈ü

Bu proje, **production-ready** bir uygulama olarak kapsamlƒ± **monitoring**, **logging** ve **observability** altyapƒ±sƒ±na sahiptir. Sistem saƒülƒ±ƒüƒ±nƒ± izlemek, performans sorunlarƒ±nƒ± tespit etmek ve hata ayƒ±klamak i√ßin modern ara√ßlar kullanƒ±lƒ±r.

## üéØ Observability Pillars

### 1. Metrics (Metrikler)
- **Prometheus** ile sistem metrikleri toplama
- **Grafana** ile g√∂rselle≈ütirme (opsiyonel)
- HTTP request metrikleri, cache hit/miss oranlarƒ±, database query s√ºreleri

### 2. Logs (Loglar)
- **Structured logging** with **Zap**
- JSON formatƒ±nda loglar
- Log levels: DEBUG, INFO, WARN, ERROR
- Request ID tracking ile distributed tracing

### 3. Traces (ƒ∞zleme)
- Request ID ile end-to-end request tracking
- Middleware chain'de request flow takibi

## üìà Prometheus Metrics

### Metrics Endpoint

```
GET /metrics
```

**√ñrnek Response**:
```
# HELP http_requests_total Total number of HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",path="/api/v1/search",status="200"} 1523

# HELP http_request_duration_seconds HTTP request duration in seconds
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{method="GET",path="/api/v1/search",le="0.005"} 1234
http_request_duration_seconds_bucket{method="GET",path="/api/v1/search",le="0.01"} 1456
http_request_duration_seconds_bucket{method="GET",path="/api/v1/search",le="0.025"} 1500
```

### Toplanan Metrikler

#### HTTP Metrikleri

**Dosya**: `internal/infrastructure/metrics/prometheus.go`

```go
// Request sayƒ±sƒ± (method, path, status code ile)
http_requests_total{method="GET", path="/api/v1/search", status="200"}

// Request s√ºresi (histogram)
http_request_duration_seconds{method="GET", path="/api/v1/search"}

// Response boyutu
http_response_size_bytes{method="GET", path="/api/v1/search"}

// Aktif request sayƒ±sƒ±
http_requests_in_flight{method="GET", path="/api/v1/search"}
```

#### Cache Metrikleri

```go
// Cache hit sayƒ±sƒ±
cache_hits_total{cache_type="redis"}

// Cache miss sayƒ±sƒ±
cache_misses_total{cache_type="redis"}

// Cache hit oranƒ± (calculated metric)
cache_hit_ratio = cache_hits_total / (cache_hits_total + cache_misses_total)
```

#### Database Metrikleri

```go
// Database query s√ºresi
db_query_duration_seconds{operation="search"}

// Database connection pool
db_connections_active
db_connections_idle
db_connections_max
```

#### Rate Limiter Metrikleri

```go
// Rate limit a≈üƒ±mlarƒ±
rate_limit_exceeded_total{endpoint="/api/v1/search"}

// Rate limit requests
rate_limit_requests_total{endpoint="/api/v1/search"}
```

### Metrics Middleware

**Dosya**: `internal/transport/middleware/metrics.go`

```go
func MetricsMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()
        
        // Request sayacƒ±nƒ± artƒ±r
        metrics.HTTPRequestsTotal.WithLabelValues(
            r.Method,
            r.URL.Path,
        ).Inc()
        
        // In-flight request sayacƒ±nƒ± artƒ±r
        metrics.HTTPRequestsInFlight.WithLabelValues(
            r.Method,
            r.URL.Path,
        ).Inc()
        defer metrics.HTTPRequestsInFlight.WithLabelValues(
            r.Method,
            r.URL.Path,
        ).Dec()
        
        // Response writer wrapper
        rw := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}
        
        // Next handler'ƒ± √ßaƒüƒ±r
        next.ServeHTTP(rw, r)
        
        // Duration'ƒ± kaydet
        duration := time.Since(start).Seconds()
        metrics.HTTPRequestDuration.WithLabelValues(
            r.Method,
            r.URL.Path,
        ).Observe(duration)
        
        // Status code ile request sayacƒ±nƒ± g√ºncelle
        metrics.HTTPRequestsTotal.WithLabelValues(
            r.Method,
            r.URL.Path,
            strconv.Itoa(rw.statusCode),
        ).Inc()
    })
}
```

## üìù Structured Logging

### Zap Logger

**Dosya**: `internal/infrastructure/logger/zap.go`

**√ñzellikler**:
- JSON formatƒ±nda structured logging
- Log levels: DEBUG, INFO, WARN, ERROR, FATAL
- Automatic field extraction (timestamp, caller, stack trace)
- High performance (zero-allocation)

**Initialization**:
```go
func NewLogger(env string) (*zap.Logger, error) {
    var config zap.Config
    
    if env == "production" {
        config = zap.NewProductionConfig()
    } else {
        config = zap.NewDevelopmentConfig()
    }
    
    config.EncoderConfig.TimeKey = "timestamp"
    config.EncoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
    
    return config.Build()
}
```

**Usage**:
```go
logger.Info("Search request received",
    zap.String("request_id", requestID),
    zap.String("query", query),
    zap.Int("page", page),
    zap.Duration("duration", duration),
)

logger.Error("Database error",
    zap.String("request_id", requestID),
    zap.Error(err),
    zap.String("operation", "search"),
)
```

### Log Levels

#### DEBUG
Geli≈ütirme sƒ±rasƒ±nda detaylƒ± bilgi i√ßin kullanƒ±lƒ±r.
```go
logger.Debug("Cache lookup",
    zap.String("key", cacheKey),
    zap.Bool("found", found),
)
```

#### INFO
Normal operasyonel bilgiler.
```go
logger.Info("Provider sync completed",
    zap.String("provider", providerName),
    zap.Int("contents", contentCount),
    zap.Duration("duration", duration),
)
```

#### WARN
Potansiyel sorunlar ama uygulama √ßalƒ±≈ümaya devam ediyor.
```go
logger.Warn("Cache miss",
    zap.String("key", cacheKey),
    zap.String("reason", "expired"),
)
```

#### ERROR
Hata durumlarƒ± ama uygulama recover edebiliyor.
```go
logger.Error("Failed to fetch provider contents",
    zap.String("provider", providerName),
    zap.Error(err),
)
```

#### FATAL
Kritik hatalar, uygulama kapanƒ±yor.
```go
logger.Fatal("Database connection failed",
    zap.Error(err),
)
```

### Log Format

**Development**:
```
2026-01-31T19:00:00.000Z    INFO    Search request received
    request_id: abc-123
    query: golang
    page: 1
    duration: 45ms
```

**Production (JSON)**:
```json
{
  "level": "info",
  "timestamp": "2026-01-31T19:00:00.000Z",
  "caller": "http/handlers.go:45",
  "msg": "Search request received",
  "request_id": "abc-123",
  "query": "golang",
  "page": 1,
  "duration": 0.045
}
```

## üîç Request Tracking

### Request ID Middleware

**Dosya**: `internal/transport/middleware/request_id.go`

Her request'e unique bir ID atanƒ±r ve t√ºm log'larda kullanƒ±lƒ±r.

```go
func RequestIDMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Request ID'yi header'dan al veya olu≈ütur
        requestID := r.Header.Get("X-Request-ID")
        if requestID == "" {
            requestID = uuid.New().String()
        }
        
        // Response header'a ekle
        w.Header().Set("X-Request-ID", requestID)
        
        // Context'e ekle
        ctx := context.WithValue(r.Context(), "request_id", requestID)
        
        // Next handler'ƒ± √ßaƒüƒ±r
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}
```

**Usage in Logs**:
```go
requestID := r.Context().Value("request_id").(string)

logger.Info("Processing request",
    zap.String("request_id", requestID),
    zap.String("path", r.URL.Path),
)
```

### Logging Middleware

**Dosya**: `internal/transport/middleware/logging.go`

Her HTTP request'i loglar.

```go
func LoggingMiddleware(logger *zap.Logger) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            start := time.Now()
            
            // Request ID'yi al
            requestID := r.Context().Value("request_id").(string)
            
            // Request'i logla
            logger.Info("Request started",
                zap.String("request_id", requestID),
                zap.String("method", r.Method),
                zap.String("path", r.URL.Path),
                zap.String("remote_addr", r.RemoteAddr),
                zap.String("user_agent", r.UserAgent()),
            )
            
            // Response writer wrapper
            rw := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}
            
            // Next handler'ƒ± √ßaƒüƒ±r
            next.ServeHTTP(rw, r)
            
            // Response'u logla
            duration := time.Since(start)
            logger.Info("Request completed",
                zap.String("request_id", requestID),
                zap.String("method", r.Method),
                zap.String("path", r.URL.Path),
                zap.Int("status", rw.statusCode),
                zap.Duration("duration", duration),
                zap.Int("response_size", rw.bytesWritten),
            )
        })
    }
}
```

## üè• Health Checks

### Health Endpoint

```
GET /api/v1/health
```

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2026-01-31T19:00:00Z",
  "checks": {
    "database": {
      "status": "healthy",
      "latency_ms": 2.5
    },
    "redis": {
      "status": "healthy",
      "latency_ms": 0.8
    }
  },
  "version": "1.0.0",
  "uptime_seconds": 3600
}
```

**Implementation**:
```go
func (h *HealthHandler) HandleHealth(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    
    response := HealthResponse{
        Status:    "healthy",
        Timestamp: time.Now(),
        Version:   "1.0.0",
        Checks:    make(map[string]HealthCheck),
    }
    
    // Database health check
    dbStart := time.Now()
    if err := h.db.PingContext(ctx); err != nil {
        response.Status = "unhealthy"
        response.Checks["database"] = HealthCheck{
            Status: "unhealthy",
            Error:  err.Error(),
        }
    } else {
        response.Checks["database"] = HealthCheck{
            Status:     "healthy",
            LatencyMs:  time.Since(dbStart).Milliseconds(),
        }
    }
    
    // Redis health check
    redisStart := time.Now()
    if err := h.redis.Ping(ctx).Err(); err != nil {
        response.Status = "unhealthy"
        response.Checks["redis"] = HealthCheck{
            Status: "unhealthy",
            Error:  err.Error(),
        }
    } else {
        response.Checks["redis"] = HealthCheck{
            Status:     "healthy",
            LatencyMs:  time.Since(redisStart).Milliseconds(),
        }
    }
    
    // HTTP status code
    statusCode := http.StatusOK
    if response.Status == "unhealthy" {
        statusCode = http.StatusServiceUnavailable
    }
    
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(statusCode)
    json.NewEncoder(w).Encode(response)
}
```

## üîß Profiling

### pprof Integration

**Dosya**: `cmd/server/main.go`

```go
import _ "net/http/pprof"

func main() {
    // pprof otomatik olarak /debug/pprof/* endpoint'lerini ekler
    
    // Server'ƒ± ba≈ülat
    log.Fatal(http.ListenAndServe(":8080", router))
}
```

### Available Endpoints

```
GET /debug/pprof/          - Index page
GET /debug/pprof/heap      - Heap profiling
GET /debug/pprof/goroutine - Goroutine profiling
GET /debug/pprof/profile   - CPU profiling (30s)
GET /debug/pprof/trace     - Execution trace
```

### Usage

```bash
# Heap profiling
go tool pprof http://localhost:8080/debug/pprof/heap

# CPU profiling (30 seconds)
go tool pprof http://localhost:8080/debug/pprof/profile?seconds=30

# Goroutine profiling
go tool pprof http://localhost:8080/debug/pprof/goroutine

# Interactive mode
(pprof) top10
(pprof) list functionName
(pprof) web
```

## üìä Grafana Dashboard (Opsiyonel)

### Prometheus + Grafana Setup

**docker-compose.yml**:
```yaml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
```

**prometheus.yml**:
```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'search-engine'
    static_configs:
      - targets: ['backend:8080']
```

### Grafana Panels

#### 1. Request Rate
```promql
rate(http_requests_total[5m])
```

#### 2. Error Rate
```promql
rate(http_requests_total{status=~"5.."}[5m])
```

#### 3. Request Duration (p95)
```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

#### 4. Cache Hit Ratio
```promql
cache_hits_total / (cache_hits_total + cache_misses_total)
```

## üö® Alerting (Opsiyonel)

### Prometheus Alerts

**alerts.yml**:
```yaml
groups:
  - name: search_engine_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} requests/sec"
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "P95 latency is {{ $value }} seconds"
      
      - alert: LowCacheHitRatio
        expr: cache_hits_total / (cache_hits_total + cache_misses_total) < 0.7
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low cache hit ratio"
          description: "Cache hit ratio is {{ $value }}"
```

## üìö Best Practices

### 1. Structured Logging

```go
// ‚ùå K√∂t√º
log.Printf("User %s searched for %s", userID, query)

// ‚úÖ ƒ∞yi
logger.Info("Search performed",
    zap.String("user_id", userID),
    zap.String("query", query),
    zap.Int("results", len(results)),
)
```

### 2. Log Levels

```go
// DEBUG: Geli≈ütirme detaylarƒ±
logger.Debug("Cache key generated", zap.String("key", key))

// INFO: Normal operasyonlar
logger.Info("Request processed", zap.Duration("duration", duration))

// WARN: Potansiyel sorunlar
logger.Warn("Slow query detected", zap.Duration("duration", duration))

// ERROR: Hatalar
logger.Error("Database error", zap.Error(err))

// FATAL: Kritik hatalar
logger.Fatal("Failed to start server", zap.Error(err))
```

### 3. Metrics Naming

```
# Pattern: <namespace>_<subsystem>_<name>_<unit>
http_requests_total
http_request_duration_seconds
cache_hits_total
db_query_duration_seconds
```

### 4. Request Context

```go
// Request ID'yi context'e ekle
ctx := context.WithValue(r.Context(), "request_id", requestID)

// T√ºm fonksiyonlarda kullan
func ProcessRequest(ctx context.Context) {
    requestID := ctx.Value("request_id").(string)
    logger.Info("Processing", zap.String("request_id", requestID))
}
```

## üîç Troubleshooting

### High Memory Usage

```bash
# Heap profiling
go tool pprof http://localhost:8080/debug/pprof/heap

# Top memory consumers
(pprof) top10

# Detailed analysis
(pprof) list functionName
```

### High CPU Usage

```bash
# CPU profiling
go tool pprof http://localhost:8080/debug/pprof/profile?seconds=30

# Top CPU consumers
(pprof) top10
```

### Goroutine Leaks

```bash
# Goroutine profiling
go tool pprof http://localhost:8080/debug/pprof/goroutine

# Check goroutine count
curl http://localhost:8080/debug/pprof/goroutine?debug=1
```

## üìà Performance Monitoring

### Key Metrics to Monitor

1. **Request Rate**: Requests per second
2. **Error Rate**: Errors per second
3. **Latency**: P50, P95, P99 response times
4. **Cache Hit Ratio**: Cache effectiveness
5. **Database Connection Pool**: Active/idle connections
6. **Goroutine Count**: Potential leaks
7. **Memory Usage**: Heap allocation

### SLO/SLA Targets

- **Availability**: 99.9% uptime
- **Latency**: P95 < 100ms, P99 < 500ms
- **Error Rate**: < 0.1%
- **Cache Hit Ratio**: > 80%
